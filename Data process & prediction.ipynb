{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainpath = os.getcwd().split('code')[0]\n",
    "user_info = pd.read_table(trainpath+'train/user_info_train.txt',names=['id','sex','job','education','marriage','hukou'],header=None,delimiter=',',encoding='utf8',delim_whitespace=False,index_col=False)\n",
    "overdue = pd.read_table(trainpath+'train/overdue_train.txt',names=['id','overdue'],header=None,delimiter=',',encoding='utf8',delim_whitespace=False,index_col=False)\n",
    "train = pd.merge(overdue,user_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_info_test = pd.read_table(trainpath+'test/user_info_test.txt',names=['id','sex','job','education','marriage','hukou'],header=None,delimiter=',',encoding='utf8',delim_whitespace=False,index_col=False)\n",
    "usersID_test = pd.read_table(trainpath+'test/usersID_test.txt',names=['id'],header=None,delimiter=',',encoding='utf8',delim_whitespace=False,index_col=False)\n",
    "\n",
    "test = pd.merge(usersID_test,user_info_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sex</th>\n",
       "      <th>job</th>\n",
       "      <th>education</th>\n",
       "      <th>marriage</th>\n",
       "      <th>hukou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55597</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55598</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55599</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55600</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55601</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  sex  job  education  marriage  hukou\n",
       "0  55597    2    2          3         1      4\n",
       "1  55598    1    2          2         3      4\n",
       "2  55599    2    2          4         2      1\n",
       "3  55600    2    4          4         3      1\n",
       "4  55601    1    2          3         1      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 放贷款时间loan_time.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loan_time_train = pd.read_table(trainpath+'train/loan_time_train.txt',names=['id','loan_time_stamp'],header=None,delimiter=',',encoding='utf8',delim_whitespace=False,index_col=False)\n",
    "train = pd.merge(train,loan_time_train)\n",
    "train['loan_time'] = train['loan_time_stamp'].apply(lambda x: time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(float(x))))\n",
    "del train['loan_time_stamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loan_time_test = pd.read_table(trainpath+'test/loan_time_test.txt',names=['id','loan_time_stamp'],header=None,delimiter=',',encoding='utf8',delim_whitespace=False,index_col=False)\n",
    "test = pd.merge(test,loan_time_test)\n",
    "test['loan_time'] = test['loan_time_stamp'].apply(lambda x: time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(float(x))))\n",
    "del test['loan_time_stamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loan_time(train,test):\n",
    "    for ds in [train,test]:\n",
    "        ds['loan_month'] = ds['loan_time'].apply(lambda x: str(x).split('-')[1])\n",
    "        ds['loan_day'] = ds['loan_time'].apply(lambda x: str(x).split('-')[2].split(' ')[0])\n",
    "        del ds['loan_time']\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = loan_time(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 信用卡账单 bill_detail.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bill_detail_train = pd.read_table(trainpath+'train/bill_detail_train.txt',names=['id','bill_time_stamp','bank_id','last_bill_money','last_repay_money','card_limit','current_bill_balance','current_lowest_repay_money','pay_count','current_bill_money','adjust_money','recurrent_interest','available_balance','borrow_cash_limit','repay_condition'],header=None,delimiter=',',encoding='utf8',delim_whitespace=False,index_col=False)\n",
    "bill_detail_test = pd.read_table(trainpath+'test/bill_detail_test.txt',names=['id','bill_time_stamp','bank_id','last_bill_money','last_repay_money','card_limit','current_bill_balance','current_lowest_repay_money','pay_count','current_bill_money','adjust_money','recurrent_interest','available_balance','borrow_cash_limit','repay_condition'],header=None,delimiter=',',encoding='utf8',delim_whitespace=False,index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['bill_count'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bill_detal_id_value_count_train = bill_detail_train['id'].value_counts()\n",
    "bill_detal_id_value_count_test = bill_detail_test['id'].value_counts()\n",
    "train['bill_count'] = train['id'].apply(lambda x: bill_detal_id_value_count_train.ix[x] if x  in bill_detal_id_value_count_train.index  else 0)\n",
    "test['bill_count'] = test['id'].apply(lambda x: bill_detal_id_value_count_test.ix[x] if x  in bill_detal_id_value_count_test.index  else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['if_have_bill_detail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bill_detail_train_id_unique = bill_detail_train['id'].unique()\n",
    "train['if_have_bill_detail'] = train['id'].apply(lambda x: 1 if x in bill_detail_train_id_unique  else 0 )\n",
    "no_bill_detail_train_id_unique = train[train['if_have_bill_detail']==0]['id'].unique()\n",
    "\n",
    "bill_detail_test_id_unique = bill_detail_test['id'].unique()\n",
    "test['if_have_bill_detail'] = test['id'].apply(lambda x: 1 if x in bill_detail_test_id_unique  else 0 )\n",
    "no_bill_detail_test_id_unique = test[test['if_have_bill_detail']==0]['id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['bill_year'] train['bill_day'] train['bill_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bill_detail_train['bill_time'] = bill_detail_train['bill_time_stamp'].apply(lambda x: time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(float(x))))\n",
    "bill_detail_test['bill_time'] = bill_detail_test['bill_time_stamp'].apply(lambda x: time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(float(x))))\n",
    "\n",
    "#bill_detail_train['bill_time'].replace('1970-01-01 08:00:00','0000-00-00 00:00:00',inplace = True)\n",
    "#bill_detail_test['bill_time'].replace('1970-01-01 08:00:00','0000-00-00 00:00:00',inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bill_detail_train['bill_year'] = bill_detail_train['bill_time'].apply(lambda x: str(x).split('-')[0])\n",
    "bill_detail_train['bill_month'] = bill_detail_train['bill_time'].apply(lambda x: str(x).split('-')[1])\n",
    "bill_detail_train['bill_day'] = bill_detail_train['bill_time'].apply(lambda x: str(x).split('-')[2].split(' ')[0])\n",
    "bill_detail_train = pd.concat((bill_detail_train,pd.get_dummies(bill_detail_train['bill_year'],prefix='bill_year_count')),axis=1)\n",
    "bill_detail_train = pd.concat((bill_detail_train,pd.get_dummies(bill_detail_train['bill_month'],prefix='bill_month_count')),axis=1)\n",
    "\n",
    "bill_detail_test['bill_year'] = bill_detail_test['bill_time'].apply(lambda x: str(x).split('-')[0])\n",
    "bill_detail_test['bill_month'] = bill_detail_test['bill_time'].apply(lambda x: str(x).split('-')[1])\n",
    "bill_detail_test['bill_day'] = bill_detail_test['bill_time'].apply(lambda x: str(x).split('-')[2].split(' ')[0])\n",
    "bill_detail_test = pd.concat((bill_detail_test,pd.get_dummies(bill_detail_test['bill_year'],prefix='bill_year_count')),axis=1)\n",
    "bill_detail_test = pd.concat((bill_detail_test,pd.get_dummies(bill_detail_test['bill_month'],prefix='bill_month_count')),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bill_year_number_train.csv 存在 \n",
      "bill_year_number_test.csv 存在 \n"
     ]
    }
   ],
   "source": [
    "def get_bill_year_number(x):\n",
    "    if x % 1000 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x][bill_year_number].sum()\n",
    "\n",
    "if os.path.exists('bill_year_number_train.csv'):\n",
    "    print 'bill_year_number_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('bill_year_number_train.csv'))\n",
    "else:    \n",
    "    for bill_year_number in pd.get_dummies(bill_detail_train['bill_year'],prefix='bill_year_count').columns.unique():\n",
    "        print bill_year_number\n",
    "        train[bill_year_number] = train['id'].apply(lambda x: get_bill_year_number(x) )\n",
    "        \n",
    "def get_bill_year_number_test(x):\n",
    "    if x % 1000 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x][bill_year_number].sum()\n",
    "\n",
    "if os.path.exists('bill_year_number_test.csv'):\n",
    "    print 'bill_year_number_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('bill_year_number_test.csv'))\n",
    "else:    \n",
    "    for bill_year_number in pd.get_dummies(bill_detail_test['bill_year'],prefix='bill_year_count').columns.unique():\n",
    "        print bill_year_number\n",
    "        test[bill_year_number] = test['id'].apply(lambda x: get_bill_year_number_test(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_bill_year_number():\n",
    "    csv_save_bill_year_number = pd.concat((train['id'],train.loc[:,pd.get_dummies(bill_detail_train['bill_year'],prefix='bill_year_count').columns.unique()]),axis=1)\n",
    "    csv_save_bill_year_number.to_csv('bill_year_number_train.csv', sep=\",\", index = False)\n",
    "#save_bill_year_number()\n",
    "\n",
    "def save_bill_year_number_test():\n",
    "    csv_save_bill_year_number = pd.concat((test['id'],test.loc[:,pd.get_dummies(bill_detail_test['bill_year'],prefix='bill_year_count').columns.unique()]),axis=1)\n",
    "    csv_save_bill_year_number.to_csv('bill_year_number_test.csv', sep=\",\", index = False)\n",
    "#save_bill_year_number_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bill_month_number_train.csv 存在 \n",
      "bill_month_number_test.csv 存在 \n"
     ]
    }
   ],
   "source": [
    "def get_bill_month_number(x):\n",
    "    if x % 1000 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x][bill_month_number].sum()\n",
    "\n",
    "if os.path.exists('bill_month_number_train.csv'):\n",
    "    print 'bill_month_number_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('bill_month_number_train.csv'))\n",
    "else:    \n",
    "    for bill_month_number in pd.get_dummies(bill_detail_train['bill_month'],prefix='bill_month_count').columns.unique():\n",
    "        print bill_month_number\n",
    "        train[bill_month_number] = train['id'].apply(lambda x: get_bill_month_number(x) )\n",
    "\n",
    "def get_bill_month_number_test(x):\n",
    "    if x % 1000 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x][bill_month_number].sum()\n",
    "\n",
    "if os.path.exists('bill_month_number_test.csv'):\n",
    "    print 'bill_month_number_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('bill_month_number_test.csv'))\n",
    "else:    \n",
    "    for bill_month_number in pd.get_dummies(bill_detail_test['bill_month'],prefix='bill_month_count').columns.unique():\n",
    "        print bill_month_number\n",
    "        test[bill_month_number] = test['id'].apply(lambda x: get_bill_month_number_test(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_bill_month_number():\n",
    "    csv_save_bill_month_number = pd.concat((train['id'],train.loc[:,pd.get_dummies(bill_detail_train['bill_month'],prefix='bill_month_count').columns.unique()]),axis=1)\n",
    "    csv_save_bill_month_number.to_csv('bill_month_number_train.csv', sep=\",\", index = False)\n",
    "#save_bill_month_number()\n",
    "\n",
    "def save_bill_month_number_test():\n",
    "    csv_save_bill_month_number = pd.concat((test['id'],test.loc[:,pd.get_dummies(bill_detail_test['bill_month'],prefix='bill_month_count').columns.unique()]),axis=1)\n",
    "    csv_save_bill_month_number.to_csv('bill_month_number_test.csv', sep=\",\", index = False)\n",
    "#save_bill_month_number_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['bank_id_number_**']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakemeup/anaconda/lib/python2.7/site-packages/pandas/core/indexing.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "bill_detail_train['bank_id'].ix[~bill_detail_train['bank_id'].isin([7,14,4,16,6,3,10,2,8,11,13,15,9,5,1,12])] = 51\n",
    "bill_detail_test['bank_id'].ix[~bill_detail_test['bank_id'].isin([7,14,4,16,6,3,10,2,8,11,13,15,9,5,1,12])] = 51\n",
    "bill_detail_train = pd.concat((bill_detail_train,pd.get_dummies(bill_detail_train['bank_id'],prefix='bank_id_number')),axis=1)\n",
    "bill_detail_test = pd.concat((bill_detail_test,pd.get_dummies(bill_detail_test['bank_id'],prefix='bank_id_number')),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank_id_number_train.csv 存在 \n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('bank_id_number_train.csv'):\n",
    "    print 'bank_id_number_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('bank_id_number_train.csv'))\n",
    "else:\n",
    "    for bank_id_number in pd.get_dummies(bill_detail_train['bank_id'],prefix='bank_id_number').columns.unique():\n",
    "        print bank_id_number\n",
    "        train[bank_id_number] = train['id'].apply(lambda x: bill_detail_train[bill_detail_train['id'] == x][bank_id_number].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank_id_number_train.csv 存在 \n",
      "bank_id_number_test.csv 存在 \n"
     ]
    }
   ],
   "source": [
    "def bank_id_number_train(x):\n",
    "    if x % 1000 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x][bank_id_number].sum()\n",
    "\n",
    "if os.path.exists('bank_id_number_train.csv'):\n",
    "    print 'bank_id_number_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('bank_id_number_train.csv'))\n",
    "else:\n",
    "    for bank_id_number in pd.get_dummies(bill_detail_train['bank_id'],prefix='bank_id_number').columns.unique():\n",
    "        print bank_id_number\n",
    "        train[bank_id_number] = train['id'].apply(lambda x: bank_id_number_train(x))\n",
    "\n",
    "def bank_id_number_test(x):\n",
    "    if x % 1000 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x][bank_id_number].sum()\n",
    "\n",
    "if os.path.exists('bank_id_number_test.csv'):\n",
    "    print 'bank_id_number_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('bank_id_number_test.csv'))\n",
    "else:\n",
    "    for bank_id_number in pd.get_dummies(bill_detail_test['bank_id'],prefix='bank_id_number').columns.unique():\n",
    "        print bank_id_number\n",
    "        test[bank_id_number] = test['id'].apply(lambda x: bank_id_number_test(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_bank_id_number_train():\n",
    "    csv_save_bank_id_number_train = pd.concat((train['id'],train.loc[:,pd.get_dummies(bill_detail_train['bank_id'],prefix='bank_id_number').columns.unique()]),axis=1)\n",
    "    csv_save_bank_id_number_train.to_csv('bank_id_number_train.csv', sep=\",\", index = False)\n",
    "#save_bank_id_number_train()\n",
    "\n",
    "def save_bank_id_number_test():\n",
    "    csv_save_bank_id_number_test = pd.concat((test['id'],test.loc[:,pd.get_dummies(bill_detail_test['bank_id'],prefix='bank_id_number').columns.unique()]),axis=1)\n",
    "    csv_save_bank_id_number_test.to_csv('bank_id_number_test.csv', sep=\",\", index = False)\n",
    "#save_bank_id_number_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['diff_bank_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff_bank_count_train.csv 存在 \n",
      "diff_bank_count_test.csv 存在 \n"
     ]
    }
   ],
   "source": [
    "bank_id_number_column_unique = pd.get_dummies(bill_detail_train['bank_id'],prefix='bank_id_number').columns.unique()\n",
    "def get_diff_bank_count_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x][bank_id_number_column_unique].max().sum()\n",
    "\n",
    "if os.path.exists('diff_bank_count_train.csv'):\n",
    "    print 'diff_bank_count_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('diff_bank_count_train.csv'))\n",
    "else:\n",
    "    train['diff_bank_count'] = train['id'].apply(lambda x: get_diff_bank_count_train(x))\n",
    "\n",
    "\n",
    "bank_id_number_column_unique = pd.get_dummies(bill_detail_test['bank_id'],prefix='bank_id_number').columns.unique()\n",
    "def get_diff_bank_count_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x][bank_id_number_column_unique].max().sum()\n",
    "\n",
    "if os.path.exists('diff_bank_count_test.csv'):\n",
    "    print 'diff_bank_count_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('diff_bank_count_test.csv'))\n",
    "else:\n",
    "    test['diff_bank_count'] = test['id'].apply(lambda x: get_diff_bank_count_test(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bank_id_number_column_unique = pd.get_dummies(bill_detail_train['bank_id'],prefix='bank_id_number').columns.unique()\n",
    "#bill_detail_train[bank_id_number_column_unique].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_diff_bank_count_train():\n",
    "    csv_save_diff_bank_count_train = pd.concat((train['id'],train.loc[:,'diff_bank_count']),axis=1)\n",
    "    csv_save_diff_bank_count_train.to_csv('diff_bank_count_train.csv', sep=\",\", index = False)\n",
    "#save_diff_bank_count_train()\n",
    "\n",
    "def save_diff_bank_count_test():\n",
    "    csv_save_diff_bank_count_test = pd.concat((test['id'],test.loc[:,'diff_bank_count']),axis=1)\n",
    "    csv_save_diff_bank_count_test.to_csv('diff_bank_count_test.csv', sep=\",\", index = False)\n",
    "#save_diff_bank_count_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['last_bill_money_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_bill_money_avg_train.csv 存在 \n",
      "last_bill_money_avg_test.csv 存在 \n"
     ]
    }
   ],
   "source": [
    "def get_last_bill_money_avg_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x]['last_bill_money'].mean()\n",
    "\n",
    "if os.path.exists('last_bill_money_avg_train.csv'):\n",
    "    print 'last_bill_money_avg_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('last_bill_money_avg_train.csv'))\n",
    "else:\n",
    "    train['last_bill_money_avg'] = train['id'].apply(lambda x: get_last_bill_money_avg_train(x))\n",
    "    \n",
    "def get_last_bill_money_avg_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x]['last_bill_money'].mean()\n",
    "\n",
    "if os.path.exists('last_bill_money_avg_test.csv'):\n",
    "    print 'last_bill_money_avg_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('last_bill_money_avg_test.csv'))\n",
    "else:\n",
    "    test['last_bill_money_avg'] = test['id'].apply(lambda x: get_last_bill_money_avg_test(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_last_bill_money_avg_train():\n",
    "    csv_save_last_bill_money_avg_train = pd.concat((train['id'],train.loc[:,'last_bill_money_avg']),axis=1)\n",
    "    csv_save_last_bill_money_avg_train.to_csv('last_bill_money_avg_train.csv', sep=\",\", index = False)\n",
    "#save_last_bill_money_avg_train()\n",
    "\n",
    "def save_last_bill_money_avg_test():\n",
    "    csv_save_last_bill_money_avg_test = pd.concat((test['id'],test.loc[:,'last_bill_money_avg']),axis=1)\n",
    "    csv_save_last_bill_money_avg_test.to_csv('last_bill_money_avg_test.csv', sep=\",\", index = False)\n",
    "#save_last_bill_money_avg_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.concat((train,pd.get_dummies(pd.qcut(train['last_bill_money_avg'],15),prefix='last_bill_money_avg')),axis=1)\n",
    "test = pd.concat((test,pd.get_dummies(pd.qcut(train['last_bill_money_avg'],15)[:test.shape[0]],prefix='last_bill_money_avg')),axis=1)\n",
    "del train['last_bill_money_avg']\n",
    "del test['last_bill_money_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['last_rest_repay_money_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_rest_repay_money_avg_train.csv 存在 \n",
      "last_rest_repay_money_avg_test.csv 存在 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_last_rest_repay_money_avg_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x]['last_rest_repay_money'].mean()\n",
    "if os.path.exists('last_rest_repay_money_avg_train.csv'):\n",
    "    print 'last_rest_repay_money_avg_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('last_rest_repay_money_avg_train.csv'))\n",
    "else:\n",
    "    bill_detail_train['last_rest_repay_money'] =bill_detail_train['last_bill_money'] - bill_detail_train['last_repay_money'] \n",
    "    train['last_rest_repay_money_avg'] = train['id'].apply(lambda x: get_last_rest_repay_money_avg_train(x))\n",
    "    \n",
    "def get_last_rest_repay_money_avg_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x]['last_rest_repay_money'].mean()\n",
    "if os.path.exists('last_rest_repay_money_avg_test.csv'):\n",
    "    print 'last_rest_repay_money_avg_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('last_rest_repay_money_avg_test.csv'))\n",
    "else:\n",
    "    bill_detail_test['last_rest_repay_money'] =bill_detail_test['last_bill_money'] - bill_detail_test['last_repay_money'] \n",
    "    test['last_rest_repay_money_avg'] = test['id'].apply(lambda x: get_last_rest_repay_money_avg_test(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_last_rest_repay_money_avg_train():\n",
    "    csv_save_last_bill_money_avg_train = pd.concat((train['id'],train.loc[:,'last_rest_repay_money_avg']),axis=1)\n",
    "    csv_save_last_bill_money_avg_train.to_csv('last_rest_repay_money_avg_train.csv', sep=\",\", index = False)\n",
    "#save_last_rest_repay_money_avg_train()\n",
    "\n",
    "def save_last_rest_repay_money_avg_test():\n",
    "    csv_save_last_bill_money_avg_test = pd.concat((test['id'],test.loc[:,'last_rest_repay_money_avg']),axis=1)\n",
    "    csv_save_last_bill_money_avg_test.to_csv('last_rest_repay_money_avg_test.csv', sep=\",\", index = False)\n",
    "#save_last_rest_repay_money_avg_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat((train,pd.get_dummies(pd.qcut(train['last_rest_repay_money_avg'],14),prefix='last_rest_repay_money_avg')),axis=1)\n",
    "test = pd.concat((test,pd.get_dummies(pd.qcut(train['last_rest_repay_money_avg'],14)[:test.shape[0]],prefix='last_rest_repay_money_avg')),axis=1)\n",
    "del train['last_rest_repay_money_avg']\n",
    "del test['last_rest_repay_money_avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['card_limit_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "card_limit_avg_train.csv 存在 \n",
      "55600\n",
      "55700\n",
      "55800\n",
      "55900\n",
      "56000\n",
      "56100\n",
      "56200\n",
      "56300\n",
      "56400\n",
      "56500\n",
      "56600\n",
      "56700\n",
      "56800\n",
      "56900\n",
      "57000\n",
      "57100\n",
      "57200\n",
      "57300\n",
      "57400\n",
      "57500\n",
      "57600\n",
      "57700\n",
      "57800\n",
      "57900\n",
      "58000\n",
      "58100\n",
      "58200\n",
      "58300\n",
      "58400\n",
      "58500\n",
      "58600\n",
      "58700\n",
      "58800\n",
      "58900\n",
      "59000\n",
      "59100\n",
      "59200\n",
      "59300\n",
      "59400\n",
      "59500\n",
      "59600\n",
      "59700\n",
      "59800\n",
      "59900\n",
      "60000\n",
      "60100\n",
      "60200\n",
      "60300\n",
      "60400\n",
      "60500\n",
      "60600\n",
      "60700\n",
      "60800\n",
      "60900\n",
      "61000\n",
      "61100\n",
      "61200\n",
      "61300\n",
      "61400\n",
      "61500\n",
      "61600\n",
      "61700\n",
      "61800\n",
      "61900\n",
      "62000\n",
      "62100\n",
      "62200\n",
      "62300\n",
      "62400\n",
      "62500\n",
      "62600\n",
      "62700\n",
      "62800\n",
      "62900\n",
      "63000\n",
      "63100\n",
      "63200\n",
      "63300\n",
      "63400\n",
      "63500\n",
      "63600\n",
      "63700\n",
      "63800\n",
      "63900\n",
      "64000\n",
      "64100\n",
      "64200\n",
      "64300\n",
      "64400\n",
      "64500\n",
      "64600\n",
      "64700\n",
      "64800\n",
      "64900\n",
      "65000\n",
      "65100\n",
      "65200\n",
      "65300\n",
      "65400\n",
      "65500\n",
      "65600\n",
      "65700\n",
      "65800\n",
      "65900\n",
      "66000\n",
      "66100\n",
      "66200\n",
      "66300\n",
      "66400\n",
      "66500\n",
      "66600\n",
      "66700\n",
      "66800\n",
      "66900\n",
      "67000\n",
      "67100\n",
      "67200\n",
      "67300\n",
      "67400\n",
      "67500\n",
      "67600\n",
      "67700\n",
      "67800\n",
      "67900\n",
      "68000\n",
      "68100\n",
      "68200\n",
      "68300\n",
      "68400\n",
      "68500\n",
      "68600\n",
      "68700\n",
      "68800\n",
      "68900\n",
      "69000\n",
      "69100\n",
      "69200\n",
      "69300\n",
      "69400\n"
     ]
    }
   ],
   "source": [
    "def get_card_limit_avg_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x]['card_limit'].mean()\n",
    "if os.path.exists('card_limit_avg_train.csv'):\n",
    "    print 'card_limit_avg_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('card_limit_avg_train.csv'))\n",
    "else:\n",
    "    train['card_limit_avg'] = train['id'].apply(lambda x: get_card_limit_avg_train(x))\n",
    " \n",
    "def get_card_limit_avg_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x]['card_limit'].mean()\n",
    "if os.path.exists('card_limit_avg_test.csv'):\n",
    "    print 'card_limit_avg_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('card_limit_avg_test.csv'))\n",
    "else:\n",
    "    test['card_limit_avg'] = test['id'].apply(lambda x: get_card_limit_avg_test(x))\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_card_limit_avg_train():\n",
    "    csv_save_last_bill_money_avg_train = pd.concat((train['id'],train.loc[:,'card_limit_avg']),axis=1)\n",
    "    csv_save_last_bill_money_avg_train.to_csv('card_limit_avg_train.csv', sep=\",\", index = False)\n",
    "save_card_limit_avg_train()\n",
    "\n",
    "def save_card_limit_avg_test():\n",
    "    csv_save_last_bill_money_avg_test = pd.concat((test['id'],test.loc[:,'card_limit_avg']),axis=1)\n",
    "    csv_save_last_bill_money_avg_test.to_csv('card_limit_avg_test.csv', sep=\",\", index = False)\n",
    "save_card_limit_avg_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.concat((train,pd.get_dummies(pd.qcut(train['card_limit_avg'],12),prefix='card_limit_avg')),axis=1)\n",
    "test = pd.concat((test,pd.get_dummies(pd.qcut(train['card_limit_avg'],12)[:test.shape[0]],prefix='card_limit_avg')),axis=1)\n",
    "del train['card_limit_avg']\n",
    "del test['card_limit_avg']\n",
    "\n",
    "\n",
    "#print train['overdue'].groupby(pd.qcut(train['card_limit_avg'],12)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['last_rest_repay_money_morethan0_count'] \\ train['last_rest_repay_money_morethan10_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_rest_repay_money_morethan0_count_train.csv 存在 \n",
      "last_rest_repay_money_morethan0_count_test.csv 存在 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_last_rest_repay_money_morethan0_count_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x][bill_detail_train['last_rest_repay_money']>0].shape[0]\n",
    "if os.path.exists('last_rest_repay_money_morethan0_count_train.csv'):\n",
    "    print 'last_rest_repay_money_morethan0_count_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('last_rest_repay_money_morethan0_count_train.csv'))\n",
    "else:\n",
    "    bill_detail_train['last_rest_repay_money'] =bill_detail_train['last_bill_money'] - bill_detail_train['last_repay_money'] \n",
    "    train['last_rest_repay_money_morethan0_count'] = train['id'].apply(lambda x: get_last_rest_repay_money_morethan0_count_train(x))\n",
    "    \n",
    "def get_last_rest_repay_money_morethan0_count_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x][bill_detail_test['last_rest_repay_money']>0].shape[0]\n",
    "if os.path.exists('last_rest_repay_money_morethan0_count_test.csv'):\n",
    "    print 'last_rest_repay_money_morethan0_count_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('last_rest_repay_money_morethan0_count_test.csv'))\n",
    "else:\n",
    "    bill_detail_test['last_rest_repay_money'] =bill_detail_test['last_bill_money'] - bill_detail_test['last_repay_money'] \n",
    "    test['last_rest_repay_money_morethan0_count'] = test['id'].apply(lambda x: get_last_rest_repay_money_morethan0_count_test(x))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_last_rest_repay_money_morethan0_count_train():\n",
    "    csv_save_last_rest_repay_money_morethan0_count_train = pd.concat((train['id'],train.loc[:,'last_rest_repay_money_morethan0_count']),axis=1)\n",
    "    csv_save_last_rest_repay_money_morethan0_count_train.to_csv('last_rest_repay_money_morethan0_count_train.csv', sep=\",\", index = False)\n",
    "#save_last_rest_repay_money_morethan0_count_train()\n",
    "\n",
    "def save_last_rest_repay_money_morethan0_count_test():\n",
    "    csv_save_last_rest_repay_money_morethan0_count_test = pd.concat((test['id'],test.loc[:,'last_rest_repay_money_morethan0_count']),axis=1)\n",
    "    csv_save_last_rest_repay_money_morethan0_count_test.to_csv('last_rest_repay_money_morethan0_count_test.csv', sep=\",\", index = False)\n",
    "#save_last_rest_repay_money_morethan0_count_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_rest_repay_money_morethan10_count_train.csv 存在 \n",
      "last_rest_repay_money_morethan10_count_test.csv 存在 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_last_rest_repay_money_morethan10_count_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x][bill_detail_train['last_rest_repay_money']>0].shape[0]\n",
    "if os.path.exists('last_rest_repay_money_morethan10_count_train.csv'):\n",
    "    print 'last_rest_repay_money_morethan10_count_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('last_rest_repay_money_morethan10_count_train.csv'))\n",
    "else:\n",
    "    bill_detail_train['last_rest_repay_money'] =bill_detail_train['last_bill_money'] - bill_detail_train['last_repay_money'] \n",
    "    train['last_rest_repay_money_morethan10_count'] = train['id'].apply(lambda x: get_last_rest_repay_money_morethan10_count_train(x))\n",
    "    \n",
    "def get_last_rest_repay_money_morethan10_count_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x][bill_detail_test['last_rest_repay_money']>0].shape[0]\n",
    "if os.path.exists('last_rest_repay_money_morethan10_count_test.csv'):\n",
    "    print 'last_rest_repay_money_morethan10_count_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('last_rest_repay_money_morethan10_count_test.csv'))\n",
    "else:\n",
    "    bill_detail_test['last_rest_repay_money'] =bill_detail_test['last_bill_money'] - bill_detail_test['last_repay_money'] \n",
    "    test['last_rest_repay_money_morethan10_count'] = test['id'].apply(lambda x: get_last_rest_repay_money_morethan10_count_test(x))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_last_rest_repay_money_morethan10_count_train():\n",
    "    csv_save_last_rest_repay_money_morethan10_count_train = pd.concat((train['id'],train.loc[:,'last_rest_repay_money_morethan10_count']),axis=1)\n",
    "    csv_save_last_rest_repay_money_morethan10_count_train.to_csv('last_rest_repay_money_morethan10_count_train.csv', sep=\",\", index = False)\n",
    "#save_last_rest_repay_money_morethan10_count_train()\n",
    "\n",
    "def save_last_rest_repay_money_morethan10_count_test():\n",
    "    csv_save_last_rest_repay_money_morethan10_count_test = pd.concat((test['id'],test.loc[:,'last_rest_repay_money_morethan10_count']),axis=1)\n",
    "    csv_save_last_rest_repay_money_morethan10_count_test.to_csv('last_rest_repay_money_morethan10_count_test.csv', sep=\",\", index = False)\n",
    "#save_last_rest_repay_money_morethan10_count_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['current_bill_balance_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "card_limit_avg_train.csv 存在 \n",
      "55600\n",
      "55700\n",
      "55800\n",
      "55900\n",
      "56000\n",
      "56100\n",
      "56200\n",
      "56300\n",
      "56400\n",
      "56500\n",
      "56600\n",
      "56700\n",
      "56800\n",
      "56900\n",
      "57000\n",
      "57100\n",
      "57200\n",
      "57300\n",
      "57400\n",
      "57500\n",
      "57600\n",
      "57700\n",
      "57800\n",
      "57900\n",
      "58000\n",
      "58100\n",
      "58200\n",
      "58300\n",
      "58400\n",
      "58500\n",
      "58600\n",
      "58700\n",
      "58800\n",
      "58900\n",
      "59000\n",
      "59100\n",
      "59200\n",
      "59300\n",
      "59400\n",
      "59500\n",
      "59600\n",
      "59700\n",
      "59800\n",
      "59900\n",
      "60000\n",
      "60100\n",
      "60200\n",
      "60300\n",
      "60400\n",
      "60500\n",
      "60600\n",
      "60700\n",
      "60800\n",
      "60900\n",
      "61000\n",
      "61100\n",
      "61200\n",
      "61300\n",
      "61400\n",
      "61500\n",
      "61600\n",
      "61700\n",
      "61800\n",
      "61900\n",
      "62000\n",
      "62100\n",
      "62200\n",
      "62300\n",
      "62400\n",
      "62500\n",
      "62600\n",
      "62700\n",
      "62800\n",
      "62900\n",
      "63000\n",
      "63100\n",
      "63200\n",
      "63300\n",
      "63400\n",
      "63500\n",
      "63600\n",
      "63700\n",
      "63800\n",
      "63900\n",
      "64000\n",
      "64100\n",
      "64200\n",
      "64300\n",
      "64400\n",
      "64500\n",
      "64600\n",
      "64700\n",
      "64800\n",
      "64900\n",
      "65000\n",
      "65100\n",
      "65200\n",
      "65300\n",
      "65400\n",
      "65500\n",
      "65600\n",
      "65700\n",
      "65800\n",
      "65900\n",
      "66000\n",
      "66100\n",
      "66200\n",
      "66300\n",
      "66400\n",
      "66500\n",
      "66600\n",
      "66700\n",
      "66800\n",
      "66900\n",
      "67000\n",
      "67100\n",
      "67200\n",
      "67300\n",
      "67400\n",
      "67500\n",
      "67600\n",
      "67700\n",
      "67800\n",
      "67900\n",
      "68000\n",
      "68100\n",
      "68200\n",
      "68300\n",
      "68400\n",
      "68500\n",
      "68600\n",
      "68700\n",
      "68800\n",
      "68900\n",
      "69000\n",
      "69100\n",
      "69200\n",
      "69300\n",
      "69400\n"
     ]
    }
   ],
   "source": [
    "def get_card_limit_avg_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x]['card_limit'].mean()\n",
    "if os.path.exists('card_limit_avg_train.csv'):\n",
    "    print 'card_limit_avg_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('card_limit_avg_train.csv'))\n",
    "else:\n",
    "    train['card_limit_avg'] = train['id'].apply(lambda x: get_card_limit_avg_train(x))\n",
    " \n",
    "def get_card_limit_avg_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x]['card_limit'].mean()\n",
    "if os.path.exists('card_limit_avg_test.csv'):\n",
    "    print 'card_limit_avg_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('card_limit_avg_test.csv'))\n",
    "else:\n",
    "    test['card_limit_avg'] = test['id'].apply(lambda x: get_card_limit_avg_test(x))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_card_limit_avg_train():\n",
    "    csv_save_last_bill_money_avg_train = pd.concat((train['id'],train.loc[:,'card_limit_avg']),axis=1)\n",
    "    csv_save_last_bill_money_avg_train.to_csv('card_limit_avg_train.csv', sep=\",\", index = False)\n",
    "#save_card_limit_avg_train()\n",
    "\n",
    "def save_card_limit_avg_test():\n",
    "    csv_save_last_bill_money_avg_test = pd.concat((test['id'],test.loc[:,'card_limit_avg']),axis=1)\n",
    "    csv_save_last_bill_money_avg_test.to_csv('card_limit_avg_test.csv', sep=\",\", index = False)\n",
    "#save_card_limit_avg_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat((train,pd.get_dummies(pd.qcut(train['card_limit_avg'],12),prefix='card_limit_avg')),axis=1)\n",
    "test = pd.concat((test,pd.get_dummies(pd.qcut(train['card_limit_avg'],12)[:test.shape[0]],prefix='card_limit_avg')),axis=1)\n",
    "del train['card_limit_avg']\n",
    "del test['card_limit_avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['current_bill_balance_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_bill_balance_avg_train.csv 存在 \n",
      "55600\n",
      "55700\n",
      "55800\n",
      "55900\n",
      "56000\n",
      "56100\n",
      "56200\n",
      "56300\n",
      "56400\n",
      "56500\n",
      "56600\n",
      "56700\n",
      "56800\n",
      "56900\n",
      "57000\n",
      "57100\n",
      "57200\n",
      "57300\n",
      "57400\n",
      "57500\n",
      "57600\n",
      "57700\n",
      "57800\n",
      "57900\n",
      "58000\n",
      "58100\n",
      "58200\n",
      "58300\n",
      "58400\n",
      "58500\n",
      "58600\n",
      "58700\n",
      "58800\n",
      "58900\n",
      "59000\n",
      "59100\n",
      "59200\n",
      "59300\n",
      "59400\n",
      "59500\n",
      "59600\n",
      "59700\n",
      "59800\n",
      "59900\n",
      "60000\n",
      "60100\n",
      "60200\n",
      "60300\n",
      "60400\n",
      "60500\n",
      "60600\n",
      "60700\n",
      "60800\n",
      "60900\n",
      "61000\n",
      "61100\n",
      "61200\n",
      "61300\n",
      "61400\n",
      "61500\n",
      "61600\n",
      "61700\n",
      "61800\n",
      "61900\n",
      "62000\n",
      "62100\n",
      "62200\n",
      "62300\n",
      "62400\n",
      "62500\n",
      "62600\n",
      "62700\n",
      "62800\n",
      "62900\n",
      "63000\n",
      "63100\n",
      "63200\n",
      "63300\n",
      "63400\n",
      "63500\n",
      "63600\n",
      "63700\n",
      "63800\n",
      "63900\n",
      "64000\n",
      "64100\n",
      "64200\n",
      "64300\n",
      "64400\n",
      "64500\n",
      "64600\n",
      "64700\n",
      "64800\n",
      "64900\n",
      "65000\n",
      "65100\n",
      "65200\n",
      "65300\n",
      "65400\n",
      "65500\n",
      "65600\n",
      "65700\n",
      "65800\n",
      "65900\n",
      "66000\n",
      "66100\n",
      "66200\n",
      "66300\n",
      "66400\n",
      "66500\n",
      "66600\n",
      "66700\n",
      "66800\n",
      "66900\n",
      "67000\n",
      "67100\n",
      "67200\n",
      "67300\n",
      "67400\n",
      "67500\n",
      "67600\n",
      "67700\n",
      "67800\n",
      "67900\n",
      "68000\n",
      "68100\n",
      "68200\n",
      "68300\n",
      "68400\n",
      "68500\n",
      "68600\n",
      "68700\n",
      "68800\n",
      "68900\n",
      "69000\n",
      "69100\n",
      "69200\n",
      "69300\n",
      "69400\n"
     ]
    }
   ],
   "source": [
    "def get_current_bill_balance_avg_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x]['card_limit'].mean()\n",
    "if os.path.exists('current_bill_balance_avg_train.csv'):\n",
    "    print 'current_bill_balance_avg_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('current_bill_balance_avg_train.csv'))\n",
    "else:\n",
    "    train['current_bill_balance_avg'] = train['id'].apply(lambda x: get_current_bill_balance_avg_train(x))\n",
    " \n",
    "def get_current_bill_balance_avg_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x]['card_limit'].mean()\n",
    "if os.path.exists('current_bill_balance_avg_test.csv'):\n",
    "    print 'current_bill_balance_avg_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('current_bill_balance_avg_test.csv'))\n",
    "else:\n",
    "    test['current_bill_balance_avg'] = test['id'].apply(lambda x: get_current_bill_balance_avg_test(x))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_current_bill_balance_avg_train():\n",
    "    csv_save_last_bill_money_avg_train = pd.concat((train['id'],train.loc[:,'current_bill_balance_avg']),axis=1)\n",
    "    csv_save_last_bill_money_avg_train.to_csv('current_bill_balance_avg_train.csv', sep=\",\", index = False)\n",
    "save_current_bill_balance_avg_train()\n",
    "\n",
    "def save_current_bill_balance_avg_test():\n",
    "    csv_save_last_bill_money_avg_test = pd.concat((test['id'],test.loc[:,'current_bill_balance_avg']),axis=1)\n",
    "    csv_save_last_bill_money_avg_test.to_csv('current_bill_balance_avg_test.csv', sep=\",\", index = False)\n",
    "save_current_bill_balance_avg_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat((train,pd.get_dummies(pd.qcut(train['current_bill_balance_avg'],12),prefix='current_bill_balance_avg')),axis=1)\n",
    "test = pd.concat((test,pd.get_dummies(pd.qcut(train['current_bill_balance_avg'],12)[:test.shape[0]],prefix='current_bill_balance_avg')),axis=1)\n",
    "del train['current_bill_balance_avg']\n",
    "del test['current_bill_balance_avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['current_bill_balance_lessthan0_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_bill_balance_lessthan0_count_train.csv 存在 \n",
      "current_bill_balance_lessthan0_count_test.csv 存在 \n"
     ]
    }
   ],
   "source": [
    "def get_current_bill_balance_lessthan0_count_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x][bill_detail_train['current_bill_balance']<0].shape[0]\n",
    "if os.path.exists('current_bill_balance_lessthan0_count_train.csv'):\n",
    "    print 'current_bill_balance_lessthan0_count_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('current_bill_balance_lessthan0_count_train.csv'))\n",
    "else:\n",
    "    train['current_bill_balance_lessthan0_count'] = train['id'].apply(lambda x: get_current_bill_balance_lessthan0_count_train(x))\n",
    "\n",
    "def get_current_bill_balance_lessthan0_count_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x][bill_detail_test['current_bill_balance']<0].shape[0]\n",
    "if os.path.exists('current_bill_balance_lessthan0_count_test.csv'):\n",
    "    print 'current_bill_balance_lessthan0_count_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('current_bill_balance_lessthan0_count_test.csv'))\n",
    "else:\n",
    "    test['current_bill_balance_lessthan0_count'] = test['id'].apply(lambda x: get_current_bill_balance_lessthan0_count_test(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_current_bill_balance_lessthan0_count_train():\n",
    "    csv_save_current_bill_balance_lessthan0_count_train = pd.concat((train['id'],train.loc[:,'current_bill_balance_lessthan0_count']),axis=1)\n",
    "    csv_save_current_bill_balance_lessthan0_count_train.to_csv('current_bill_balance_lessthan0_count_train.csv', sep=\",\", index = False)\n",
    "#save_current_bill_balance_lessthan0_count_train()\n",
    "\n",
    "def save_current_bill_balance_lessthan0_count_test():\n",
    "    csv_save_current_bill_balance_lessthan0_count_test = pd.concat((test['id'],test.loc[:,'current_bill_balance_lessthan0_count']),axis=1)\n",
    "    csv_save_current_bill_balance_lessthan0_count_test.to_csv('current_bill_balance_lessthan0_count_test.csv', sep=\",\", index = False)\n",
    "save_current_bill_balance_lessthan0_count_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['current_card_limit_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bill_detail_train['current_card_limit'] = bill_detail_train['current_lowest_repay_money']-bill_detail_train['current_bill_money']\n",
    "bill_detail_test['current_card_limit'] = bill_detail_test['current_lowest_repay_money']-bill_detail_test['current_bill_money']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_card_limit_avg_train.csv 存在 \n",
      "55600\n",
      "55700\n",
      "55800\n",
      "55900\n",
      "56000\n",
      "56100\n",
      "56200\n",
      "56300\n",
      "56400\n",
      "56500\n",
      "56600\n",
      "56700\n",
      "56800\n",
      "56900\n",
      "57000\n",
      "57100\n",
      "57200\n",
      "57300\n",
      "57400\n",
      "57500\n",
      "57600\n",
      "57700\n",
      "57800\n",
      "57900\n",
      "58000\n",
      "58100\n",
      "58200\n",
      "58300\n",
      "58400\n",
      "58500\n",
      "58600\n",
      "58700\n",
      "58800\n",
      "58900\n",
      "59000\n",
      "59100\n",
      "59200\n",
      "59300\n",
      "59400\n",
      "59500\n",
      "59600\n",
      "59700\n",
      "59800\n",
      "59900\n",
      "60000\n",
      "60100\n",
      "60200\n",
      "60300\n",
      "60400\n",
      "60500\n",
      "60600\n",
      "60700\n",
      "60800\n",
      "60900\n",
      "61000\n",
      "61100\n",
      "61200\n",
      "61300\n",
      "61400\n",
      "61500\n",
      "61600\n",
      "61700\n",
      "61800\n",
      "61900\n",
      "62000\n",
      "62100\n",
      "62200\n",
      "62300\n",
      "62400\n",
      "62500\n",
      "62600\n",
      "62700\n",
      "62800\n",
      "62900\n",
      "63000\n",
      "63100\n",
      "63200\n",
      "63300\n",
      "63400\n",
      "63500\n",
      "63600\n",
      "63700\n",
      "63800\n",
      "63900\n",
      "64000\n",
      "64100\n",
      "64200\n",
      "64300\n",
      "64400\n",
      "64500\n",
      "64600\n",
      "64700\n",
      "64800\n",
      "64900\n",
      "65000\n",
      "65100\n",
      "65200\n",
      "65300\n",
      "65400\n",
      "65500\n",
      "65600\n",
      "65700\n",
      "65800\n",
      "65900\n",
      "66000\n",
      "66100\n",
      "66200\n",
      "66300\n",
      "66400\n",
      "66500\n",
      "66600\n",
      "66700\n",
      "66800\n",
      "66900\n",
      "67000\n",
      "67100\n",
      "67200\n",
      "67300\n",
      "67400\n",
      "67500\n",
      "67600\n",
      "67700\n",
      "67800\n",
      "67900\n",
      "68000\n",
      "68100\n",
      "68200\n",
      "68300\n",
      "68400\n",
      "68500\n",
      "68600\n",
      "68700\n",
      "68800\n",
      "68900\n",
      "69000\n",
      "69100\n",
      "69200\n",
      "69300\n",
      "69400\n"
     ]
    }
   ],
   "source": [
    "def get_current_card_limit_avg_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x]['current_card_limit'].mean()\n",
    "if os.path.exists('current_card_limit_avg_train.csv'):\n",
    "    print 'current_card_limit_avg_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('current_card_limit_avg_train.csv'))\n",
    "else:\n",
    "    train['current_card_limit_avg'] = train['id'].apply(lambda x: get_current_card_limit_avg_train(x))\n",
    " \n",
    "def get_current_card_limit_avg_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x]['current_card_limit'].mean()\n",
    "if os.path.exists('current_card_limit_avg_test.csv'):\n",
    "    print 'current_card_limit_avg_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('current_card_limit_avg_test.csv'))\n",
    "else:\n",
    "    test['current_card_limit_avg'] = test['id'].apply(lambda x: get_current_card_limit_avg_test(x))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_current_card_limit_avg_train():\n",
    "    csv_save_last_bill_money_avg_train = pd.concat((train['id'],train.loc[:,'current_card_limit_avg']),axis=1)\n",
    "    csv_save_last_bill_money_avg_train.to_csv('current_card_limit_avg_train.csv', sep=\",\", index = False)\n",
    "#save_current_card_limit_avg_train()\n",
    "\n",
    "def save_current_card_limit_avg_test():\n",
    "    csv_save_last_bill_money_avg_test = pd.concat((test['id'],test.loc[:,'current_card_limit_avg']),axis=1)\n",
    "    csv_save_last_bill_money_avg_test.to_csv('current_card_limit_avg_test.csv', sep=\",\", index = False)\n",
    "#save_current_card_limit_avg_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat((train,pd.get_dummies(pd.qcut(train['current_card_limit_avg'],9),prefix='current_card_limit_avg')),axis=1)\n",
    "test = pd.concat((test,pd.get_dummies(pd.qcut(train['current_card_limit_avg'],9)[:test.shape[0]],prefix='current_card_limit_avg')),axis=1)\n",
    "del train['current_card_limit_avg']\n",
    "del test['current_card_limit_avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['pay_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pay_count_avg_train.csv 存在 \n",
      "55600\n",
      "55700\n",
      "55800\n",
      "55900\n",
      "56000\n",
      "56100\n",
      "56200\n",
      "56300\n",
      "56400\n",
      "56500\n",
      "56600\n",
      "56700\n",
      "56800\n",
      "56900\n",
      "57000\n",
      "57100\n",
      "57200\n",
      "57300\n",
      "57400\n",
      "57500\n",
      "57600\n",
      "57700\n",
      "57800\n",
      "57900\n",
      "58000\n",
      "58100\n",
      "58200\n",
      "58300\n",
      "58400\n",
      "58500\n",
      "58600\n",
      "58700\n",
      "58800\n",
      "58900\n",
      "59000\n",
      "59100\n",
      "59200\n",
      "59300\n",
      "59400\n",
      "59500\n",
      "59600\n",
      "59700\n",
      "59800\n",
      "59900\n",
      "60000\n",
      "60100\n",
      "60200\n",
      "60300\n",
      "60400\n",
      "60500\n",
      "60600\n",
      "60700\n",
      "60800\n",
      "60900\n",
      "61000\n",
      "61100\n",
      "61200\n",
      "61300\n",
      "61400\n",
      "61500\n",
      "61600\n",
      "61700\n",
      "61800\n",
      "61900\n",
      "62000\n",
      "62100\n",
      "62200\n",
      "62300\n",
      "62400\n",
      "62500\n",
      "62600\n",
      "62700\n",
      "62800\n",
      "62900\n",
      "63000\n",
      "63100\n",
      "63200\n",
      "63300\n",
      "63400\n",
      "63500\n",
      "63600\n",
      "63700\n",
      "63800\n",
      "63900\n",
      "64000\n",
      "64100\n",
      "64200\n",
      "64300\n",
      "64400\n",
      "64500\n",
      "64600\n",
      "64700\n",
      "64800\n",
      "64900\n",
      "65000\n",
      "65100\n",
      "65200\n",
      "65300\n",
      "65400\n",
      "65500\n",
      "65600\n",
      "65700\n",
      "65800\n",
      "65900\n",
      "66000\n",
      "66100\n",
      "66200\n",
      "66300\n",
      "66400\n",
      "66500\n",
      "66600\n",
      "66700\n",
      "66800\n",
      "66900\n",
      "67000\n",
      "67100\n",
      "67200\n",
      "67300\n",
      "67400\n",
      "67500\n",
      "67600\n",
      "67700\n",
      "67800\n",
      "67900\n",
      "68000\n",
      "68100\n",
      "68200\n",
      "68300\n",
      "68400\n",
      "68500\n",
      "68600\n",
      "68700\n",
      "68800\n",
      "68900\n",
      "69000\n",
      "69100\n",
      "69200\n",
      "69300\n",
      "69400\n"
     ]
    }
   ],
   "source": [
    "def get_pay_count_avg_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x]['pay_count'].mean()\n",
    "if os.path.exists('pay_count_avg_train.csv'):\n",
    "    print 'pay_count_avg_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('pay_count_avg_train.csv'))\n",
    "else:\n",
    "    train['pay_count_avg'] = train['id'].apply(lambda x: get_pay_count_avg_train(x))\n",
    " \n",
    "def get_pay_count_avg_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x]['pay_count'].mean()\n",
    "if os.path.exists('pay_count_avg_test.csv'):\n",
    "    print 'pay_count_avg_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('pay_count_avg_test.csv'))\n",
    "else:\n",
    "    test['pay_count_avg'] = test['id'].apply(lambda x: get_pay_count_avg_test(x))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_pay_count_avg_train():\n",
    "    csv_save_last_bill_money_avg_train = pd.concat((train['id'],train.loc[:,'pay_count_avg']),axis=1)\n",
    "    csv_save_last_bill_money_avg_train.to_csv('pay_count_avg_train.csv', sep=\",\", index = False)\n",
    "save_pay_count_avg_train()\n",
    "\n",
    "def save_pay_count_avg_test():\n",
    "    csv_save_last_bill_money_avg_test = pd.concat((test['id'],test.loc[:,'pay_count_avg']),axis=1)\n",
    "    csv_save_last_bill_money_avg_test.to_csv('pay_count_avg_test.csv', sep=\",\", index = False)\n",
    "save_pay_count_avg_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.concat((train,pd.get_dummies(pd.cut(train['pay_count_avg'],bins=[-1,0,0.2,1,1.2,1.5,1000]),prefix='pay_count_avg')),axis=1)\n",
    "test = pd.concat((test,pd.get_dummies(pd.cut(test['pay_count_avg'],bins=[-1,0,0.2,1,1.2,1.5,1000])[:test.shape[0]],prefix='pay_count_avg')),axis=1)\n",
    "del train['pay_count_avg']\n",
    "del test['pay_count_avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['adjust_money_morethan0_count']  train['adjust_money_lessthan0_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjust_money_morethan0_count_train.csv 存在 \n",
      "adjust_money_morethan0_count_test.csv 存在 \n"
     ]
    }
   ],
   "source": [
    "def get_adjust_money_morethan0_count_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x][bill_detail_train['adjust_money']>0].shape[0]\n",
    "if os.path.exists('adjust_money_morethan0_count_train.csv'):\n",
    "    print 'adjust_money_morethan0_count_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('adjust_money_morethan0_count_train.csv'))\n",
    "else:\n",
    "    train['adjust_money_morethan0_count'] = train['id'].apply(lambda x: get_adjust_money_morethan0_count_train(x))\n",
    "\n",
    "def get_adjust_money_morethan0_count_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x][bill_detail_test['adjust_money']>0].shape[0]\n",
    "if os.path.exists('adjust_money_morethan0_count_test.csv'):\n",
    "    print 'adjust_money_morethan0_count_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('adjust_money_morethan0_count_test.csv'))\n",
    "else:\n",
    "    test['adjust_money_morethan0_count'] = test['id'].apply(lambda x: get_adjust_money_morethan0_count_test(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_adjust_money_morethan0_count_train():\n",
    "    csv_save_adjust_money_morethan0_count_train = pd.concat((train['id'],train.loc[:,'adjust_money_morethan0_count']),axis=1)\n",
    "    csv_save_adjust_money_morethan0_count_train.to_csv('adjust_money_morethan0_count_train.csv', sep=\",\", index = False)\n",
    "#save_adjust_money_morethan0_count_train()\n",
    "\n",
    "def save_adjust_money_morethan0_count_test():\n",
    "    csv_save_adjust_money_morethan0_count_test = pd.concat((test['id'],test.loc[:,'adjust_money_morethan0_count']),axis=1)\n",
    "    csv_save_adjust_money_morethan0_count_test.to_csv('adjust_money_morethan0_count_test.csv', sep=\",\", index = False)\n",
    "save_adjust_money_morethan0_count_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjust_money_lessthan0_count_train.csv 存在 \n",
      "adjust_money_lessthan0_count_test.csv 存在 \n"
     ]
    }
   ],
   "source": [
    "def get_adjust_money_lessthan0_count_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x][bill_detail_train['adjust_money']>0].shape[0]\n",
    "if os.path.exists('adjust_money_lessthan0_count_train.csv'):\n",
    "    print 'adjust_money_lessthan0_count_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('adjust_money_lessthan0_count_train.csv'))\n",
    "else:\n",
    "    train['adjust_money_lessthan0_count'] = train['id'].apply(lambda x: get_adjust_money_lessthan0_count_train(x))\n",
    "\n",
    "def get_adjust_money_lessthan0_count_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x][bill_detail_test['adjust_money']>0].shape[0]\n",
    "if os.path.exists('adjust_money_lessthan0_count_test.csv'):\n",
    "    print 'adjust_money_lessthan0_count_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('adjust_money_lessthan0_count_test.csv'))\n",
    "else:\n",
    "    test['adjust_money_lessthan0_count'] = test['id'].apply(lambda x: get_adjust_money_lessthan0_count_test(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_adjust_money_lessthan0_count_train():\n",
    "    csv_save_adjust_money_lessthan0_count_train = pd.concat((train['id'],train.loc[:,'adjust_money_lessthan0_count']),axis=1)\n",
    "    csv_save_adjust_money_lessthan0_count_train.to_csv('adjust_money_lessthan0_count_train.csv', sep=\",\", index = False)\n",
    "#save_adjust_money_lessthan0_count_train()\n",
    "\n",
    "def save_adjust_money_lessthan0_count_test():\n",
    "    csv_save_adjust_money_lessthan0_count_test = pd.concat((test['id'],test.loc[:,'adjust_money_lessthan0_count']),axis=1)\n",
    "    csv_save_adjust_money_lessthan0_count_test.to_csv('adjust_money_lessthan0_count_test.csv', sep=\",\", index = False)\n",
    "save_adjust_money_lessthan0_count_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['recurrent_interest_morethan0_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recurrent_interest_morethan0_count_train.csv 存在 \n",
      "recurrent_interest_morethan0_count_test.csv 存在 \n"
     ]
    }
   ],
   "source": [
    "def get_recurrent_interest_morethan0_count_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x][bill_detail_train['recurrent_interest']>0].shape[0]\n",
    "if os.path.exists('recurrent_interest_morethan0_count_train.csv'):\n",
    "    print 'recurrent_interest_morethan0_count_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('recurrent_interest_morethan0_count_train.csv'))\n",
    "else:\n",
    "    train['recurrent_interest_morethan0_count'] = train['id'].apply(lambda x: get_recurrent_interest_morethan0_count_train(x))\n",
    "\n",
    "def get_recurrent_interest_morethan0_count_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x][bill_detail_test['recurrent_interest']>0].shape[0]\n",
    "if os.path.exists('recurrent_interest_morethan0_count_test.csv'):\n",
    "    print 'recurrent_interest_morethan0_count_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('recurrent_interest_morethan0_count_test.csv'))\n",
    "else:\n",
    "    test['recurrent_interest_morethan0_count'] = test['id'].apply(lambda x: get_recurrent_interest_morethan0_count_test(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_recurrent_interest_morethan0_count_train():\n",
    "    csv_save_recurrent_interest_morethan0_count_train = pd.concat((train['id'],train.loc[:,'recurrent_interest_morethan0_count']),axis=1)\n",
    "    csv_save_recurrent_interest_morethan0_count_train.to_csv('recurrent_interest_morethan0_count_train.csv', sep=\",\", index = False)\n",
    "save_recurrent_interest_morethan0_count_train()\n",
    "\n",
    "def save_recurrent_interest_morethan0_count_test():\n",
    "    csv_save_recurrent_interest_morethan0_count_test = pd.concat((test['id'],test.loc[:,'recurrent_interest_morethan0_count']),axis=1)\n",
    "    csv_save_recurrent_interest_morethan0_count_test.to_csv('recurrent_interest_morethan0_count_test.csv', sep=\",\", index = False)\n",
    "save_recurrent_interest_morethan0_count_test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['available_balance_morethan0_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available_balance_morethan0_count_train.csv 存在 \n",
      "available_balance_morethan0_count_test.csv 存在 \n"
     ]
    }
   ],
   "source": [
    "def get_available_balance_morethan0_count_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x][bill_detail_train['available_balance']>0].shape[0]\n",
    "if os.path.exists('available_balance_morethan0_count_train.csv'):\n",
    "    print 'available_balance_morethan0_count_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('available_balance_morethan0_count_train.csv'))\n",
    "else:\n",
    "    train['available_balance_morethan0_count'] = train['id'].apply(lambda x: get_available_balance_morethan0_count_train(x))\n",
    "\n",
    "def get_available_balance_morethan0_count_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x][bill_detail_test['available_balance']>0].shape[0]\n",
    "if os.path.exists('available_balance_morethan0_count_test.csv'):\n",
    "    print 'available_balance_morethan0_count_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('available_balance_morethan0_count_test.csv'))\n",
    "else:\n",
    "    test['available_balance_morethan0_count'] = test['id'].apply(lambda x: get_available_balance_morethan0_count_test(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_available_balance_morethan0_count_train():\n",
    "    csv_save_available_balance_morethan0_count_train = pd.concat((train['id'],train.loc[:,'available_balance_morethan0_count']),axis=1)\n",
    "    csv_save_available_balance_morethan0_count_train.to_csv('available_balance_morethan0_count_train.csv', sep=\",\", index = False)\n",
    "#save_available_balance_morethan0_count_train()\n",
    "\n",
    "def save_available_balance_morethan0_count_test():\n",
    "    csv_save_available_balance_morethan0_count_test = pd.concat((test['id'],test.loc[:,'available_balance_morethan0_count']),axis=1)\n",
    "    csv_save_available_balance_morethan0_count_test.to_csv('available_balance_morethan0_count_test.csv', sep=\",\", index = False)\n",
    "#save_available_balance_morethan0_count_test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['borrow_cash_limit_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borrow_cash_limit_avg_train.csv 存在 \n",
      "borrow_cash_limit_avg_test.csv 存在 \n"
     ]
    }
   ],
   "source": [
    "def get_borrow_cash_limit_avg_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_train[bill_detail_train['id'] == x]['borrow_cash_limit'].mean()\n",
    "\n",
    "if os.path.exists('borrow_cash_limit_avg_train.csv'):\n",
    "    print 'borrow_cash_limit_avg_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('borrow_cash_limit_avg_train.csv'))\n",
    "else:\n",
    "    train['borrow_cash_limit_avg'] = train['id'].apply(lambda x: get_borrow_cash_limit_avg_train(x))\n",
    "    \n",
    "def get_borrow_cash_limit_avg_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bill_detail_test[bill_detail_test['id'] == x]['borrow_cash_limit'].mean()\n",
    "\n",
    "if os.path.exists('borrow_cash_limit_avg_test.csv'):\n",
    "    print 'borrow_cash_limit_avg_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('borrow_cash_limit_avg_test.csv'))\n",
    "else:\n",
    "    test['borrow_cash_limit_avg'] = test['id'].apply(lambda x: get_borrow_cash_limit_avg_test(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_borrow_cash_limit_avg_train():\n",
    "    csv_save_borrow_cash_limit_avg_train = pd.concat((train['id'],train.loc[:,'borrow_cash_limit_avg']),axis=1)\n",
    "    csv_save_borrow_cash_limit_avg_train.to_csv('borrow_cash_limit_avg_train.csv', sep=\",\", index = False)\n",
    "#save_borrow_cash_limit_avg_train()\n",
    "\n",
    "def save_borrow_cash_limit_avg_test():\n",
    "    csv_save_borrow_cash_limit_avg_test = pd.concat((test['id'],test.loc[:,'borrow_cash_limit_avg']),axis=1)\n",
    "    csv_save_borrow_cash_limit_avg_test.to_csv('borrow_cash_limit_avg_test.csv', sep=\",\", index = False)\n",
    "#save_borrow_cash_limit_avg_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins2 =  [0,8,17,25]\n",
    "train = pd.concat((train,pd.get_dummies(pd.cut(train['borrow_cash_limit_avg'],bins=bins2),prefix='borrow_cash_limit_avg')),axis=1)\n",
    "test = pd.concat((test,pd.get_dummies(pd.cut(test['borrow_cash_limit_avg'],bins=bins2)[:test.shape[0]],prefix='borrow_cash_limit_avg')),axis=1)\n",
    "del train['borrow_cash_limit_avg']\n",
    "del test['borrow_cash_limit_avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['repay_condition_1'] 经过分析很可能没用？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#test['repay_condition_1'].iloc[60000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64011 60389 65340 57192 56516 60398 63310 68769 59116 68020 68780 62056\n",
      " 57216 63352 56563 68801 56028 62089 57949 63611 62365 65063 57552 60156\n",
      " 65870 63762 55776 57703 67158]\n"
     ]
    }
   ],
   "source": [
    "train['repay_condition_1'] = 0\n",
    "repay_condition_1_id = bill_detail_train[bill_detail_train['repay_condition']>0]['id'].unique()\n",
    "train.loc[train['id'].isin(repay_condition_1_id),'repay_condition_1']=1\n",
    "\n",
    "test['repay_condition_1'] = 0\n",
    "repay_condition_1_id = bill_detail_test[bill_detail_test['repay_condition']>0]['id'].unique()\n",
    "print repay_condition_1_id\n",
    "\n",
    "test.loc[test['id'].isin(repay_condition_1_id),'repay_condition_1']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bank_detail.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bank_detail_train = pd.read_table(trainpath+'train/bank_detail_train.txt',names=['id','bank_time_stamp','business_type','business_money','wage_sign'],header=None,delimiter=',',encoding='utf8',delim_whitespace=False,index_col=False)\n",
    "bank_detail_test = pd.read_table(trainpath+'test/bank_detail_test.txt',names=['id','bank_time_stamp','business_type','business_money','wage_sign'],header=None,delimiter=',',encoding='utf8',delim_whitespace=False,index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['if_have_bank_detail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bank_detail_train_id_unique = bank_detail_train['id'].unique()\n",
    "train['if_have_bank_detail'] = train['id'].apply(lambda x: 1 if x in bank_detail_train_id_unique  else 0 )\n",
    "no_bank_detail_train_id_unique = train[train['if_have_bank_detail']==0]['id'].unique()\n",
    "\n",
    "bank_detail_test_id_unique = bank_detail_test['id'].unique()\n",
    "test['if_have_bank_detail'] = test['id'].apply(lambda x: 1 if x in bank_detail_test_id_unique  else 0 )\n",
    "no_bank_detail_test_id_unique = test[test['if_have_bank_detail']==0]['id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['bank_count'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bank_detal_id_value_count_train = bank_detail_train['id'].value_counts()\n",
    "train['bank_count'] = train['id'].apply(lambda x: bank_detal_id_value_count_train.ix[x] if x  in bank_detal_id_value_count_train.index  else 0)\n",
    "\n",
    "bank_detal_id_value_count_test = bank_detail_test['id'].value_counts()\n",
    "test['bank_count'] = test['id'].apply(lambda x: bank_detal_id_value_count_test.ix[x] if x  in bank_detal_id_value_count_test.index  else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['bank_year_count_**'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bank_detail_train['bank_time'] = bank_detail_train['bank_time_stamp'].apply(lambda x: time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(float(x))))\n",
    "bank_detail_test['bank_time'] = bank_detail_test['bank_time_stamp'].apply(lambda x: time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(float(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bank_detail_train['bank_year'] = bank_detail_train['bank_time'].apply(lambda x: str(x).split('-')[0])\n",
    "bank_detail_train['bank_month'] = bank_detail_train['bank_time'].apply(lambda x: str(x).split('-')[1])\n",
    "bank_detail_train['bank_day'] = bank_detail_train['bank_time'].apply(lambda x: str(x).split('-')[2].split(' ')[0])\n",
    "bank_detail_train['bank_hour'] = bank_detail_train['bank_time'].apply(lambda x: str(x).split(' ')[1].split(':')[0])\n",
    "bank_detail_train['bank_minutes'] = bank_detail_train['bank_time'].apply(lambda x: str(x).split(':')[1])\n",
    "#bank_detail_train['bank_day'] = bank_detail_train['bank_time'].apply(lambda x: str(x).split('-')[2].split(' ')[0])\n",
    "\n",
    "bank_detail_test['bank_year'] = bank_detail_test['bank_time'].apply(lambda x: str(x).split('-')[0])\n",
    "bank_detail_test['bank_month'] = bank_detail_test['bank_time'].apply(lambda x: str(x).split('-')[1])\n",
    "bank_detail_test['bank_day'] = bank_detail_test['bank_time'].apply(lambda x: str(x).split('-')[2].split(' ')[0])\n",
    "bank_detail_test['bank_hour'] = bank_detail_test['bank_time'].apply(lambda x: str(x).split(' ')[1].split(':')[0])\n",
    "bank_detail_test['bank_minutes'] = bank_detail_test['bank_time'].apply(lambda x: str(x).split(':')[1])\n",
    "#bank_detail_test['bank_day'] = bank_detail_test['bank_time'].apply(lambda x: str(x).split('-')[2].split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bank_detail_train = pd.concat((bank_detail_train,pd.get_dummies(bank_detail_train['bank_year'],prefix='bank_year_count')),axis=1)\n",
    "bank_detail_test = pd.concat((bank_detail_test,pd.get_dummies(bank_detail_test['bank_year'],prefix='bank_year_count')),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13899"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank_year_number_train.csv 存在 \n",
      "bank_year_number_test.csv 存在 \n"
     ]
    }
   ],
   "source": [
    "def get_bank_year_number_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bank_detail_train[bank_detail_train['id'] == x][bank_year_number].sum()\n",
    "\n",
    "if os.path.exists('bank_year_number_train.csv'):\n",
    "    print 'bank_year_number_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('bank_year_number_train.csv'))\n",
    "else:    \n",
    "    for bank_year_number in pd.get_dummies(bank_detail_train['bank_year'],prefix='bank_year_count').columns.unique():\n",
    "        print bank_year_number\n",
    "        train[bank_year_number] = train['id'].apply(lambda x: get_bank_year_number_train(x) )\n",
    "\n",
    "def get_bank_year_number_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bank_detail_test[bank_detail_test['id'] == x][bank_year_number].sum()\n",
    "\n",
    "if os.path.exists('bank_year_number_test.csv'):\n",
    "    print 'bank_year_number_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('bank_year_number_test.csv'))\n",
    "else:    \n",
    "    for bank_year_number in pd.get_dummies(bank_detail_test['bank_year'],prefix='bank_year_count').columns.unique():\n",
    "        print bank_year_number\n",
    "        test[bank_year_number] = test['id'].apply(lambda x: get_bank_year_number_test(x) )\n",
    "        print 'over'\n",
    "        print test[bank_year_number].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13899"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_bank_year_number():\n",
    "    csv_save_bank_year_number = pd.concat((train['id'],train.loc[:,pd.get_dummies(bank_detail_train['bank_year'],prefix='bank_year_count').columns.unique()]),axis=1)\n",
    "    csv_save_bank_year_number.to_csv('bank_year_number_train.csv', sep=\",\", index = False)\n",
    "#save_bank_year_number()\n",
    "\n",
    "def save_bank_year_number_test():\n",
    "    csv_save_bank_year_number = pd.concat((test['id'],test.loc[:,pd.get_dummies(bank_detail_test['bank_year'],prefix='bank_year_count').columns.unique()]),axis=1)\n",
    "    csv_save_bank_year_number.to_csv('bank_year_number_test.csv', sep=\",\", index = False)\n",
    "#save_bank_year_number_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins3 = [-1,0.5,320,20000]\n",
    "train = pd.concat((train,pd.get_dummies(pd.cut(train['bank_year_count_2157'],bins=bins3),prefix='bank_year_count_2157')),axis=1)\n",
    "test = pd.concat((test,pd.get_dummies(pd.cut(test['bank_year_count_2157'],bins=bins3)[:test.shape[0]],prefix='bank_year_count_2157')),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del train['bank_year_count_2157']\n",
    "del test['bank_year_count_2157']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year in ['bank_year_count_2156','bank_year_count_1970']:\n",
    "    for ds in [train,test]:\n",
    "        ds.loc[ds[year]>0,year] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13899"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train['business_type_1_count'] train['business_type_0_count']  ..> dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train['bank_year_count_1970'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wakemeup/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n"
     ]
    }
   ],
   "source": [
    "def get_business_type_1_count_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bank_detail_train[bank_detail_train['id'] == x][bank_detail_train['business_type']==1].shape[0]\n",
    "if os.path.exists('business_type_1_count_train.csv'):\n",
    "    print 'business_type_1_count_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('business_type_1_count_train.csv'))\n",
    "else:\n",
    "    train['business_type_1_count'] = train['id'].apply(lambda x: get_business_type_1_count_train(x))\n",
    "\n",
    "def get_business_type_1_count_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bank_detail_test[bank_detail_test['id'] == x][bank_detail_test['business_type']==1].shape[0]\n",
    "if os.path.exists('business_type_1_count_test.csv'):\n",
    "    print 'business_type_1_count_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('business_type_1_count_test.csv'))\n",
    "else:\n",
    "    test['business_type_1_count'] = test['id'].apply(lambda x: get_business_type_1_count_test(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_business_type_1_count_train():\n",
    "    csv_save_business_type_1_count_train = pd.concat((train['id'],train.loc[:,'business_type_1_count']),axis=1)\n",
    "    csv_save_business_type_1_count_train.to_csv('business_type_1_count_train.csv', sep=\",\", index = False)\n",
    "#save_business_type_1_count_train()\n",
    "\n",
    "def save_business_type_1_count_test():\n",
    "    csv_save_business_type_1_count_test = pd.concat((test['id'],test.loc[:,'business_type_1_count']),axis=1)\n",
    "    csv_save_business_type_1_count_test.to_csv('business_type_1_count_test.csv', sep=\",\", index = False)\n",
    "#save_business_type_1_count_test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.loc[train['business_type_1_count']>0,'business_type_1_count'] = 1\n",
    "test.loc[test['business_type_1_count']>0,'business_type_1_count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "def get_business_type_0_count_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bank_detail_train[bank_detail_train['id'] == x][bank_detail_train['business_type']==1].shape[0]\n",
    "if os.path.exists('business_type_0_count_train.csv'):\n",
    "    print 'business_type_0_count_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('business_type_0_count_train.csv'))\n",
    "else:\n",
    "    train['business_type_0_count'] = train['id'].apply(lambda x: get_business_type_0_count_train(x))\n",
    "\n",
    "def get_business_type_0_count_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bank_detail_test[bank_detail_test['id'] == x][bank_detail_test['business_type']==1].shape[0]\n",
    "if os.path.exists('business_type_0_count_test.csv'):\n",
    "    print 'business_type_0_count_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('business_type_0_count_test.csv'))\n",
    "else:\n",
    "    test['business_type_0_count'] = test['id'].apply(lambda x: get_business_type_0_count_test(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def save_business_type_0_count_train():\n",
    "    csv_save_business_type_0_count_train = pd.concat((train['id'],train.loc[:,'business_type_0_count']),axis=1)\n",
    "    csv_save_business_type_0_count_train.to_csv('business_type_0_count_train.csv', sep=\",\", index = False)\n",
    "save_business_type_0_count_train()\n",
    "\n",
    "def save_business_type_0_count_test():\n",
    "    csv_save_business_type_0_count_test = pd.concat((test['id'],test.loc[:,'business_type_0_count']),axis=1)\n",
    "    csv_save_business_type_0_count_test.to_csv('business_type_0_count_test.csv', sep=\",\", index = False)\n",
    "save_business_type_0_count_test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### train['business_money_avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\"\"\"\n",
    "def get_business_money_avg_train(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bank_detail_train[bank_detail_train['id'] == x]['business_money'].mean()\n",
    "\n",
    "if os.path.exists('business_money_avg_train.csv'):\n",
    "    print 'business_money_avg_train.csv 存在 '\n",
    "    train = pd.merge(train,pd.read_csv('business_money_avg_train.csv'))\n",
    "else:\n",
    "    train['business_money_avg'] = train['id'].apply(lambda x: get_business_money_avg_train(x))\n",
    "    \n",
    "def get_business_money_avg_test(x):\n",
    "    if x % 100 == 0: print x\n",
    "    return bank_detail_test[bank_detail_test['id'] == x]['business_money'].mean()\n",
    "\n",
    "if os.path.exists('business_money_avg_test.csv'):\n",
    "    print 'business_money_avg_test.csv 存在 '\n",
    "    test = pd.merge(test,pd.read_csv('business_money_avg_test.csv'))\n",
    "else:\n",
    "    test['business_money_avg'] = test['id'].apply(lambda x: get_business_money_avg_test(x))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def save_business_money_avg_train():\n",
    "    csv_save_business_money_avg_train = pd.concat((train['id'],train.loc[:,'business_money_avg']),axis=1)\n",
    "    csv_save_business_money_avg_train.to_csv('business_money_avg_train.csv', sep=\",\", index = False)\n",
    "save_business_money_avg_train()\n",
    "\n",
    "def save_business_money_avg_test():\n",
    "    csv_save_business_money_avg_test = pd.concat((test['id'],test.loc[:,'business_money_avg']),axis=1)\n",
    "    csv_save_business_money_avg_test.to_csv('business_money_avg_test.csv', sep=\",\", index = False)\n",
    "save_business_money_avg_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test['last_rest_repay_money_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 检查test 于train 的column是否匹配\n",
    "for i in  range(1,len(test.columns.unique())):\n",
    "    if train.columns.unique()[i+1] != test.columns.unique()[i]:\n",
    "        print   train.columns.unique()[i+1],test.columns.unique()[i]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.columns.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#del train['loan_time']\n",
    "#del test['loan_time']\n",
    "test.columns.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(criterion='gini', \n",
    "                             n_estimators=1000,\n",
    "                             min_samples_split=15,\n",
    "                             min_samples_leaf=2,\n",
    "                             max_features='auto',\n",
    "                             oob_score=True,\n",
    "                             random_state=1,\n",
    "                              n_jobs=-1)\n",
    "rf.fit(train.iloc[:, 2:], train.iloc[:, 1])\n",
    "#rf.fit(test.iloc[:, 2:], test.iloc[:, 1])\n",
    "print(\"%.4f\" % rf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat((pd.DataFrame(train.iloc[:, 2:].columns, columns = ['variable']), \n",
    "           pd.DataFrame(rf.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False).to_csv('feature_importance_2.csv', sep=\",\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "记录一些历史值：\n",
    "0.872\n",
    "0.8722\n",
    "0.8722\n",
    "0.8723\n",
    "0.8723\n",
    "0.8722 #rf.fit(train.iloc[:, 2:-7], train.iloc[:, 1])\n",
    "0.8722 #rf.fit(train.iloc[:, 2:], train.iloc[:, 1])\n",
    "0.8753 加入bank business type\n",
    "0.8754\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = rf.predict_proba(test.iloc[:,1:])[:,1]\n",
    "print 'predictions =', predictions\n",
    "#predictions_overdue_rate = np.sum(predictions)/float(len(predictions))\n",
    "#print predictions_overdue_rate\n",
    "predictions = pd.DataFrame(predictions, columns=[u'probability'])\n",
    "predictions = pd.concat((test['id'], predictions), axis = 1)\n",
    "predictions.to_csv('y_test_3.csv', sep=\",\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = rf.predict_proba(train.iloc[:,2:])[:,1]\n",
    "print 'predictions =', predictions\n",
    "#predictions_overdue_rate = np.sum(predictions)/float(len(predictions))\n",
    "#print predictions_overdue_rate\n",
    "predictions = pd.DataFrame(predictions, columns=[u'probability'])\n",
    "predictions = pd.concat((train['id'], predictions), axis = 1)\n",
    "predictions.to_csv('y_test_for_ks_score_check.csv', sep=\",\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
